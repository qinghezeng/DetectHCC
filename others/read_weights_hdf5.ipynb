{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read weights from hdf5 file and convert them into bit vectors (for FPGA implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'E:\\\\deeplearning\\\\Hepatocarcinomes\\\\models\\\\5x\\\\vgg16_dense_bn\\\\weights.15-0.8841.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.group.Group'>\n",
      "Keys: <KeysViewHDF5 ['activation_1', 'activation_2', 'block1_conv1', 'block1_conv2', 'block1_pool', 'block2_conv1', 'block2_conv2', 'block2_pool', 'block3_conv1', 'block3_conv2', 'block3_conv3', 'block3_pool', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block4_pool', 'block5_conv1', 'block5_conv2', 'block5_conv3', 'block5_pool', 'dense1_bn', 'dense2_bn', 'dense_1', 'dense_2', 'dense_3', 'dropout_1', 'dropout_2', 'flatten_1', 'input_1']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(filename, 'r')\n",
    "\n",
    "#List all groups\n",
    "print(type(f[list(f.keys())[0]])) #Groups are like Python dictionaries. traverse down till reaching a dataset\n",
    "print(\"Keys: %s\" % f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract all dataset names \n",
    "def traverse_datasets(hdf_file):\n",
    "\n",
    "    def h5py_dataset_iterator(g, prefix=''):\n",
    "        for key in g.keys():\n",
    "            item = g[key]\n",
    "            path = f'{prefix}/{key}'\n",
    "            if isinstance(item, h5py.Dataset): # test for dataset\n",
    "                yield (path, item)\n",
    "            elif isinstance(item, h5py.Group): # test for group (go down)\n",
    "                yield from h5py_dataset_iterator(item, path)\n",
    "\n",
    "    with h5py.File(hdf_file, 'r') as f:\n",
    "        for path, _ in h5py_dataset_iterator(f):\n",
    "            yield path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset=traverse_datasets(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/block1_conv2/block1_conv2/kernel:0\n"
     ]
    }
   ],
   "source": [
    "print(next(dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"kernel:0\": shape (3, 3, 64, 128), type \"<f4\">"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[next(dset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seave weights into (8+24) bit vectors\n",
    "import math\n",
    "with open(\"E:\\\\test\\\\dense2.txt\", \"w\") as text_file:\n",
    "    for j in range(f['dense_2/dense_2/kernel:0'].shape[1]):\n",
    "        for i in range(f['dense_2/dense_2/kernel:0'].shape[0]):\n",
    "            a,b=math.modf(f['dense_2/dense_2/kernel:0'][i, j])\n",
    "            if b < 0:\n",
    "                inte = str(bin(int(b))[3:])\n",
    "                if len(inte) <= 7:\n",
    "                    inte = '1'+inte.zfill(7)\n",
    "                else:\n",
    "                    inte = '1'+inte[:7]\n",
    "            else:\n",
    "                inte = str(bin(int(b))[2:])\n",
    "                if len(inte) <= 8:\n",
    "                    inte = inte.zfill(8)\n",
    "                else:\n",
    "                    inte = inte[:8]\n",
    "            frac = str(bin(int(math.modf(abs(a)*10e8)[1]))[2:]).zfill(24)\n",
    "            if len(frac) <= 24:\n",
    "                frac = frac.zfill(24)\n",
    "            else:\n",
    "                frac = frac[:24]\n",
    "            text_file.write(inte+frac+',')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:r-tensorflow]",
   "language": "python",
   "name": "conda-env-r-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
